# "Towards Safe Neural Network Applications for Autonomous Mobile Systems" - Full Reference List

This project contains the full list of references for the paper "Towards Safe Neural Network Applications for Autonomous Mobile Systems: Literature Review and Research Agenda"
The references list is categorized in accordane to the proposed taxonomy in Figure 3 and uses the Springer Reference Format.

## In-Text References

[1] ISO 3691-4-Industrial trucks - Safety requirements and verification - Part 4: Driverless industrial trucks and their systems 53.060(3691-4)

[2] Fragapane G, Koster R de, Sgarbossa F (2024) Autonomous Mobile Robots for Material Handling in Intralogistics. Springer International, Cham, pp 251-274

[3] Lieret M, Fertsch J, Franke J (2020) Fault detection for autonomous multirotors using a redundant flight control architecture. In: 2020 IEEE 16th International Conference on Automation Science and Engineering (CASE). IEEE, pp 29–34

[4] Schwindt-Drews S, Storms K, Peters S et al. (2024) Acceptance and Trust: Drivers' First Contact with Released Automated Vehicles in Naturalistic Traffic. IEEE Trans Intell Transp. Syst 25:18601-18610. https://doi.org/10.1109/TITS.2024.3443927

[5] Huang K, Shi B, Li X et al. (2022) Multi-modal Sensor Fusion for Auto Driving Perception: A Survey

[6] LeCun Y, Bengio Y, Hinton G (2015) Deep learning. Nature 521:436-444. https://doi.org/10.1038/nature14539

[7] vom Brocke J, Simons A, Niehaves B et al. (2009) Reconstructing the Giant: On the importance of Riguor in Documenting in the Literature Search Process

[8] Webster J, Watson RT (2002) Analyzing the Past to Prepare the Future: Writing a Literature Review. MIS Quarterly 26. https://doi.org/10.2307/4132319

---

## Theoretical Frameworks

### Development Strategies

[9] Awadid A, Robert B (2025) On Assessing ML Model Robustness: A Methodological Framework (Academic Track). Schloss Dagstuhl - Leibniz-Zentrum für Informatik. OASIcs, Volume 126, SAIA 2024 126. https://doi.org/10.4230/OASIcs.SAIA.2024.1

[10] Awadid A, Robert B, Tachet D et al. (2024) Towards Engineering Processes to Guide the Development of Trustworthy ML Systems. In: 2024 IEEE International Symposium on Systems Engineering (ISSE). IEEE, pp 1-6

[11] Cioroaica E, Buhnova B, Schneider D et al. (2022) Towards the Concept of Trust Assurance Case. In: 2022 IEEE International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom). IEEE, pp 1581-1586

[12] Gracic E, Svensson F, Ehrich J et al. (2020) Concept for Safety-Related Development of Deep Neural Networks in the Automotive. In: 2020 Fourth International Conference on Multimedia Computing, Networking and Applications (MCNA). IEEE, pp 10-15

[13] Langford MA, Cheng BH (2022) A Modular and Composable Approach to Develop Trusted Artificial Intelligence. In: 2022 IEEE International Conference on Autonomic Computing and Self-Organizing Systems (ACSOS). IEEE, pp 121-130

[14] Langford MA, Zilberman S, Cheng B (2024) Anunnaki: A Modular Framework for Developing Trusted Artificial Intelligence. ACM Trans Auton Adapt Syst 19:1-34. https://doi.org/10.1145/3649453

[15] Wozniak A-L, Segura S, Mazo R (2024) Robustness Assessment of Al-Based 2D Object Detection Systems: A Method and Lessons Learned from Two Industrial Cases. Electronics 13:1368. https://doi.org/10.3390/electronics13071368

### Certification Frameworks

[16] lyenghar P, Gracic E, Pawelke G (2024) A Systematic Approach to Enhancing ISO 26262 With Machine Learning-Specific Life Cycle Phases and Testing Methods. IEEE Access 12:179600-179627. https://doi.org/10.1109/ACCESS.2024.3506333

[17] Nyakundi NB, Reza H (2024) Development of an Effective Safety Assessment Capable of Measuring the Safety of Al-Based Systems. In: 2024 IEEE International Conference on Electro Information Technology (eIT). IEEE, pp 1-8

[18] Radlak K, Szczepankiewicz M, Jones T et al. (2020) Organization of machine learning based product development as per ISO 26262 and ISO/PAS 21448. In: 2020 IEEE 25th Pacific Rim International Symposium on Dependable Computing (PRDC). IEEE, pp 110-119

[19] Socha K, Borg M, Henriksson J (2022) SMIRK: A machine learning-based pedestrian automatic emergency braking system with a complete safety case. Software Impacts 13:100352. https://doi.org/10.1016/j.simpa.2022.100352

[20] Ward FR, Habli I (2020) An Assurance Case Pattern for the Interpretability of Machine Learning in Safety-Critical Systems. In: Casimiro A, Ortmeier F, Schoitsch E et al. (eds) Computer Safety, Reliability, and Security. SAFECOMP 2020 Workshops, vol 12235. Springer International Publishing, Cham, pp 395-407

### Surveys

[21] Boudardara F, Boussif A, Meyer P-J et al. (2024) A Review of Abstraction Methods Toward Verifying Neural Networks. ACM Trans Embed Comput Syst 23:1-19. https://doi.org/10.1145/3617508

[22] Chia WMD, Keoh SL, Goh C et al. (2022) Risk Assessment Methodologies for Autonomous Driving: A Survey. IEEE Trans Intell Transport Syst 23:16923-16939. https://doi.org/10.1109/TITS.2022.3163747

[23] Jha S (2019) Trust, Resilience and Interpretability of AI Models. In: Zamani M, Zufferey D (eds) Numerical Software Verification, vol 11652. Springer International Publishing, Cham, pp 3-25

[24] Pereira A, Thomas C (2020) Challenges of Machine Learning Applied to Safety-Critical Cyber-Physical Systems. MAKE 2:579-602. https://doi.org/10.3390/make2040031

[25] Perez-Cerrolaza J, Abella J, Borg M et al. (2024) Artificial Intelligence for Safety-Critical Systems in Industrial and Transportation Domains: A Survey. ACM Comput Surv 56:1-40. https://doi.org/10.1145/3626314

[26] Sutthithatip S, Perinpanayagam S, Aslam S (2022) (Explainable) Artificial Intelligence in Aerospace Safety-Critical Systems. In: 2022 IEEE Aerospace Conference (AERO). IEEE, pp 1-12

[27] Tambon F, Laberge G, Le An et al. (2022) How to certify machine learning based safety-critical systems? A systematic literature review. Autom Softw Eng 29. https://doi.org/10.1007/s10515-022-00337-x

[28] Wang Y, Chung SH (2022) Artificial intelligence in safety-critical systems: a systematic review. IMDS 122:442-470. https://doi.org/10.1108/IMDS-07-2021-0419

[29] Wäschle M, Thaler F, Berres A et al. (2022) A review on Al Safety in highly automated driving. Front Artif Intell 5:952773. https://doi.org/10.3389/frai.2022.952773

[30] Wu T., Dong Y., Dong Z. et al. (2020) Testing artificial intelligence system towards safety and robustness: State of the art. IAENG International Journal of Computer Science 2020

[31] Yatbaz HY, Dianati M, Woodman R (2024) Introspection of DNN-Based Perception Functions in Automated Driving Systems: State-of-the-Art and Open Research Challenges. IEEE Trans Intell Transport Syst 25:1112-1130. https://doi.org/10.1109/TITS.2023.3315070

---

## System Architecture

### Redundant Design

[32] Aldomà A, Brando A, Cazorla FJ et al. (2024) Safety-Relevant Al-Based System Robustification with Neural Network Ensembles. In: 2024 IEEE 30th International Symposium on On-Line Testing and Robust System Design (IOLTS). IEEE, pp 1-3

[33] Brando A, Serra I, Mezzetti E et al. (2023) On Neural Networks Redundancy and Diversity for Their Use in Safety-Critical Systems. Computer 56:41-50. https://doi.org/10.1109/MC.2023.3236523

[34] Gutiérrez-Zaballa J, Basterretxea K, Echanobe J (2024) Reliable Explainability of Deep Learning Spatial-Spectral Classifiers for Improved Semantic Segmentation in Autonomous Driving. In: 2024 14th Workshop on Hyperspectral Imaging and Signal Processing: Evolution in Remote Sensing (WHISPERS). IEEE, pp 1–8

[35] Mehune P, Dorle S (2024) Robust and Adaptive Neural Networks for Self-Driving Cars in Challenging Road Conditions. In: 2024 2nd International Conference on Computer, Communication and Control (IC4). IEEE, pp 1–5

### Deterministic Concepts

[36] Aksjonov A, Kyrki V (2023) A Safety-Critical Decision-Making and Control Framework Combining Machine-Learning-Based and Rule-Based Algorithms. SAE Int J Veh Dyn., Stab., and NVH 7. https://doi.org/10.4271/10-07-03-0018

[37] Biondi A, Nesti F, Cicero G et al. (2020) A Safe, Secure, and Predictable Software Architecture for Deep Learning in Safety-Critical Systems. IEEE Embedded Syst Lett 12:78–82. https://doi.org/10.1109/LES.2019.2953253

[38] Christakis M, Eniser HF, Hermanns H et al. (2021) Automated Safety Verification of Programs Invoking Neural Networks. In: Silva A, Leino KRM (eds) Computer Aided Verification, vol 12759. Springer International Publishing, Cham, pp 201–224

[39] Costa de Araujo JP, Balu BV, Reichmann E et al. (2024) Applying Concept-Based Models for Enhanced Safety Argumentation. In: 2024 IEEE 35th International Symposium on Software Reliability Engineering (ISSRE). IEEE, pp 272–283

[40] Donti P.L., Roderick M., Fazlyab M. et al. Enforcing Robust Control Gurantess within Neural Network Policies. ICLR 2021 - 9th International Conference on Learning Representations 2021

[41] Faller R (2024) Explainable Statistical Evaluation and Enhancement of Automated Driving System Safety Architectures. In: Tallón-Ballesteros AJ (ed) Fuzzy Systems and Data Mining X. IOS Press

[42] Ferreira RS (2020) Towards safety monitoring of ML-based perception tasks of autonomous systems. In: 2020 IEEE International Symposium on Software Reliability Engineering Workshops (ISSREW). IEEE, pp 135–138

[43] Kurd Z, Kelly T, Austin J (2006) Developing artificial neural networks for safety critical systems. Neural Comput & Applic 16:11–19. https://doi.org/10.1007/s00521-006-0039-9

[44] Kuutti S, Bowden R, Joshi H et al. (2019) Safe Deep Neural Network-Driven Autonomous Vehicles Using Software Safety Cages. In: Yin H, Camacho D, Tino P et al. (eds) Intelligent Data Engineering and Automated Learning – IDEAL 2019, vol 11872. Springer International Publishing, Cham, pp 150–160

[45] Liu Y, Wang Z, Cai M et al. (2025) A Hybrid Target Selection Model of Functional Safety Compliance for Autonomous Driving System. ACM Trans Embed Comput Syst 24:1–27. https://doi.org/10.1145/3716631

[46] Peruffo A, Ahmed D, Abate A (2021) Automated and Formal Synthesis of Neural Barrier Certificates for Dynamical Models. In: Groote JF, Larsen KG (eds) Tools and Algorithms for the Construction and Analysis of Systems, vol 12651. Springer International Publishing, Cham, pp 370–388

[47] Schmidt LM, Kontes G, Plinge A et al. (2021) Can You Trust Your Autonomous Car? Interpretable and Verifiably Safe Reinforcement Learning. In: 2021 IEEE Intelligent Vehicles Symposium (IV). IEEE, pp 171–178

[48] Topin N, Milani S, Fang F et al. (2021) Iterative Bounding MDPs: Learning Interpretable Policies via Non-Interpretable Methods. AAAI 35:9923–9931. https://doi.org/10.1609/aaai.v35i11.17192

### Neural Network

#### Error-targeted Retraining

[49] Jia Y, Poskitt CM, Zhang P et al. (2023) Boosting Adversarial Training in Safety-Critical Systems Through Boundary Data Selection. IEEE Robot Autom Lett 8:8350–8357. https://doi.org/10.1109/LRA.2023.3327934

[50] Liang Z, Wu T, Zhao C et al. (2025) BIRDNN: Behavior-Imitation Based Repair for Deep Neural Networks. Neural Netw 183:106949. https://doi.org/10.1016/j.neunet.2024.106949

#### Resilient Architecture Design

[51] Ghavami B, Sadati M, Fang Z et al. (2022) FitAct: Error Resilient Deep Neural Networks via Fine-Grained Post-Trainable Activation Functions. In: 2022 Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEE, pp 1239–1244

[52] Radlak K, Szczepankiewicz M, Smolka B (2021 - 2021) Defending against sparse adversarial attacks using impulsive noise reduction filters. In: Kehtarnavaz N, Carlsohn MF (eds) Real-Time Image Processing and Deep Learning 2021. SPIE, p 23

#### Robustness Verification

[53] Arcaini P, Bombarda A, Bonfanti S et al. (2020) Dealing with Robustness of Convolutional Neural Networks for Image Classification. In: 2020 IEEE International Conference On Artificial Intelligence Testing (AITest). IEEE, pp 7–14

[54] Chan KH, Cheng BHC (2024) Expound: A Black-Box Approach for Generating Diversity-Driven Adversarial Examples. In: Arcaini P, Yue T, Fredericks EM (eds) Search-Based Software Engineering, vol 14415. Springer Nature Switzerland, Cham, pp 19–34

[55] Everett M, Habibi G, How JP (2021) Robustness Analysis of Neural Networks via Efficient Partitioning With Applications in Control Systems. IEEE Control Syst Lett 5:2114–2119. https://doi.org/10.1109/LCSYS.2020.3045323

[56] Fahmy H, Pastore F, Briand L et al. (2023) Simulator-based Explanation and Debugging of Hazard-triggering Events in DNN-based Safety-critical Systems. ACM Trans Softw Eng Methodol 32:1–47. https://doi.org/10.1145/3569935

[57] Fazlyab M, Morari M, Pappas GJ (2022) Safety Verification and Robustness Analysis of Neural Networks via Quadratic Constraints and Semidefinite Programming. IEEE Trans Automat Contr 67:1–15. https://doi.org/10.1109/TAC.2020.3046193

[58] Guo X, Zhou Z, Zhang Y et al. (2023) OccRob: Efficient SMT-Based Occlusion Robustness Verification of Deep Neural Networks. In: Sankaranarayanan S, Sharygina N (eds) Tools and Algorithms for the Construction and Analysis of Systems, vol 13993. Springer Nature Switzerland, Cham, pp 208–226

[59] Kang S, Feldt R, Yoo S (2020) SINVAD. In: Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops. ACM, New York, NY, USA, pp 521–528

[60] Levy N, Katz G (2023) RoMA: A Method for Neural Network Robustness Measurement and Assessment. In: Tanveer M, Agarwal S, Ozawa S et al. (eds) Neural Information Processing, vol 1791. Springer Nature Singapore, Singapore, pp 92–105

[61] Nguyen TM, Luu Q-H, Vu HL (2024) MetaCamFuse: A Framework for Evaluating Autonomous Driving Perceptions. In: 2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC). IEEE, pp 184–190

[62] Paterson C, Wu H, Grese J et al. (2021) DeepCert: Verification of Contextually Relevant Robustness for Neural Network Image Classifiers. In: Habli I, Sujan M, Bitsch F (eds) Computer Safety, Reliability, and Security, vol 12852. Springer International Publishing, Cham, pp 3–17

[63] Tran H-D, Yang X, Manzanas Lopez D et al. (2020) NNV: The Neural Network Verification Tool for Deep Neural Networks and Learning-Enabled Cyber-Physical Systems. In: Lahiri SK, Wang C (eds) Computer Aided Verification, vol 12224. Springer International Publishing, Cham, pp 3–17

[64] Wang Z, Huang C, Zhu Q (2022) Efficient Global Robustness Certification of Neural Networks via Interleaving Twin-Network Encoding. In: 2022 Design, Automation & Test in Europe Conference & Exhibition (DATE). IEEE, pp 1087–1092

[65] Wang X, Chen L, Wang T et al. (2021) An Efficient Method to Measure Robustness of ReLU-Based Classifiers via Search Space Pruning. In: 2021 International Joint Conference on Neural Networks (IJCNN). IEEE, pp 1–8

[66] Xu Y, Wei Z, Li Z et al. (2023) Neural network robustness evaluation based on interval analysis. Neural Comput & Applic 35:19481–19496. https://doi.org/10.1007/s00521-023-08737-0

[67] Zhao Z, Zhang Y, Chen G et al. (2022) CLEVEREST: Accelerating CEGAR-based Neural Network Verification via Adversarial Attacks. In: Singh G, Urban C (eds) Static Analysis, vol 13790. Springer Nature Switzerland, Cham, pp 449–473

#### Feature Extraction

[68] Attaoui MO, Fahmy H, Pastore F et al. (2024) Supporting Safety Analysis of Image-processing DNNs through Clustering-based Approaches. ACM Trans Softw Eng Methodol 33:1–48. https://doi.org/10.1145/3643671

[69] Bassan S, Katz G (2023) Towards Formal XAI: Formally Approximate Minimal Explanations of Neural Networks. In: Sankaranarayanan S, Sharygina N (eds) Tools and Algorithms for the Construction and Analysis of Systems, vol 13993. Springer Nature Switzerland, Cham, pp 187–207

[70] Fazlyab M, Morari M, Pappas GJ (2019) Probabilistic Verification and Reachability Analysis of Neural Networks via Semidefinite Programming. In: 2019 IEEE 58th Conference on Decision and Control (CDC). IEEE, pp 2726–2731

[71] Jia Y, McDermid J, Lawton T et al. (2022) The Role of Explainability in Assuring Safety of Machine Learning in Healthcare. IEEE Trans Emerg Topics Comput 10:1746–1760. https://doi.org/10.1109/TETC.2022.3171315

[72] Johnson TT, Lopez DM, Tran H-D (2024) Tutorial: Safe, Secure, and Trustworthy Artificial Intelligence (AI) via Formal Verification of Neural Networks and Autonomous Cyber-Physical Systems (CPS) with NNV. In: 2024 54th Annual IEEE/IFIP International Conference on Dependable Systems and Networks - Supplemental Volume (DSN-S). IEEE, pp 65–66

[73] Kuwajima H, Tanaka M, Okutomi M (2019) Improving transparency of deep neural inference process. Prog Artif Intell 8:273–285. https://doi.org/10.1007/s13748-019-00179-x

[74] Narteni S, Orani V, Vaccari I et al. (2022) Sensitivity of Logic Learning Machine for Reliability in Safety-Critical Systems. IEEE Intell Syst 37:66–74. https://doi.org/10.1109/MIS.2022.3159098

[75] Rengasamy D, Rothwell BC, Figueredo GP (2021) Towards a More Reliable Interpretation of Machine Learning Outputs for Safety-Critical Systems Using Feature Importance Fusion. Applied Sciences 11:11854. https://doi.org/10.3390/app112411854

[76] Samadi A, Koufos K, Debattista K et al. (2025) Counterfactual Explainer for Deep Reinforcement Learning Models using Policy Distillation. ACM Trans Intell Syst Technol 16:1–22. https://doi.org/10.1145/3709146

[77] Tran L., Dolph C., Zhao D. Enhancing neural network explainability with variational autoencoders. AIAA Scitech 2021 Forum 2021

[78] Wang T.-H., Xiao W., Seyde T. et al. (2023) Measuring Interpretability of Neural Policies of Robots with Disentangled Representation. Proceedings of Machine Learning Research 2023

[79] Wickramasinghe CS, Amarasinghe K, Marino DL et al. (2021) Explainable Unsupervised Machine Learning for Cyber-Physical Systems. IEEE Access 9:131824–131843. https://doi.org/10.1109/ACCESS.2021.3112397

#### Out-of-Distribution Detection

[80] Boursinos D, Koutsoukos X (2020) Trusted Confidence Bounds for Learning Enabled Cyber-Physical Systems. In: 2020 IEEE Security and Privacy Workshops (SPW). IEEE, pp 228–233

[81] Chan R, Rottmann M, Gottschalk H (2021) Entropy Maximization and Meta Classification for Out-of-Distribution Detection in Semantic Segmentation. In: 2021 IEEE/CVF International Conference on Computer Vision (ICCV). IEEE, pp 5108–5117

[82] Chen S, Min H, Fang Y et al. (2024) Uncertainty-aware Sensor Data Anomaly Detection for Autonomous Vehicles. In: 2024 IEEE Intelligent Vehicles Symposium (IV). IEEE, pp 478–483

[83] Cobb AD, Jalaian B, Bastian ND et al. (2021) Toward Safe Decision-Making via Uncertainty Quantification in Machine Learning. In: Lawless WF, Mittu R, Sofge DA et al. (eds) Systems Engineering and Artificial Intelligence. Springer International Publishing, Cham, pp 379–399

[84] Deuschel J, Foltyn A, Roscher K et al. (2024) The Role of Uncertainty Quantification for Trustworthy AI. In: Mutschler C, Münzenmayer C, Uhlmann N et al. (eds) Unlocking Artificial Intelligence. Springer Nature Switzerland, Cham, pp 95–115

[85] Henriksson J, Berger C, Borg M et al. (2021) Performance analysis of out-of-distribution detection on trained neural networks. Information and Software Technology 130:106409. https://doi.org/10.1016/j.infsof.2020.106409

[86] Iino S, Nomoto H, Fukui T et al. (2024) Towards Explainable Anomaly Detection in Safety-critical Systems. IJPHM 15. https://doi.org/10.36001/ijphm.2024.v15i3.3857

[87] Jöckel L, Kläs M (2021) Could We Relieve AI/ML Models of the Responsibility of Providing Dependable Uncertainty Estimates? A Study on Outside-Model Uncertainty Estimates. In: Habli I, Sujan M, Bitsch F (eds) Computer Safety, Reliability, and Security, vol 12852. Springer International Publishing, Cham, pp 18–33

[88] Langford MA, Cheng BH (2021) “Know What You Know”: Predicting Behavior for Learning-Enabled Systems When Facing Uncertainty. In: 2021 International Symposium on Software Engineering for Adaptive and Self-Managing Systems (SEAMS). IEEE, pp 78–89

[89] Ugrenovic D, Vankeirsbilck J, Vanoost D et al. (2021) Towards classification trustworthiness: one-class classifier ensemble. In: 2021 XXX International Scientific Conference Electronics (ET). IEEE, pp 1–6
